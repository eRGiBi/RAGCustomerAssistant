{
    "exp_name": "bm25resulted86f2f6ffe9",
    "results": {
        "LLMContextPrecisionWithReference": 0.6318681318333333,
        "LLMContextRecall": 0.7198039215686275,
        "Faithfulness": 0.5585119047619048,
        "BleuScore": 0.09568529648054626,
        "RougeScore": 0.18712634199432843
    },
    "parameters": {
        "retriever_name": "bm25",
        "top_k": 3,
        "embedding_dimension": 512,
        "dataset_cleaned": true,
        "bm25_params": {
            "k1": 1.3,
            "b": 0.7,
            "epsilon": 0.25
        },
        "tokenizer": "word_tokenize",
        "llm_parameters": {
            "temperature": 0.1,
            "top_p": 0.9,
            "max_output_tokens": 500
        }
    }
}